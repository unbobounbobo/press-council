# 天才エンジニアが作ったLLM Councilを魔改造してプレスリリース作成ツールを作ってみた

複数のAIに原稿を書かせて、別のAIたちに匿名で評価させる。

そんなツールがXで話題になっています。

https://x.com/fukkyy/status/1993126252916638091

元ネタは、Tesla AI責任者・OpenAI創設メンバーだったAndrej Karpathy氏が公開した「LLM Council」です。

複数のAIに同じ質問を投げて、お互いの回答を匿名で評価させます。「AIの答えが正しいかわからない」問題を、AI同士の相互チェックで解決しようというツールです。

広報PR業務は、プレスリリース作成をはじめ原稿執筆の機会が多いです。こうした相互評価の仕組みが役立つかもしれません。

そう思って魔改造したのが「Press Council」です。4つのAIがプレスリリース案を書き、5人の記者AI（日経記者、生活部記者、Web記者など）が「誰が書いたか知らない状態」で評価・ランキング。最後に編集長AIが全ての評価を踏まえて最終版を仕上げます。

記者に送る前に、記者目線でAIにチェックさせる。そんなツールです。

---

## 1. Karpathy氏の「LLM Council」とは

まず、ベースになったツールの話からです。

Karpathy氏が公開した「[LLM Council](https://github.com/karpathy/llm-council)」。仕組みはシンプルです。

1. 複数のLLM（Claude、GPT、Geminiなど）に同じ質問を投げる
2. 各LLMが他のLLMの回答を**匿名で**評価・ランキング
3. 評価結果をもとに最終回答を生成

「AIに聞いても答えが正しいかわからない」

この問題に対して、複数AIの相互チェックで信頼性を高めようというアプローチです。

### 良いところ

**単一視点の弊害を解消できます**

1つのモデルだけでは「意見が1つ、盲点が1つ」です。複数のモデルに同じ質問を投げて互いに批評させることで、ハルシネーションやバイアスを相互監視できます。

**匿名レビューで忖度を防ぎます**

各モデルは「誰が書いたか」を知らずに評価します。「Claudeの回答だから高評価」といったバイアスが発生しません。

### 一方で課題も

- **コストと速度**: 単一モデルの何倍ものAPI呼び出しが発生します
- **セットアップの手間**: PythonとJavaScript両方の環境が必要です
- **サポートなし**: Karpathy氏いわく「これはVibe Code。サポートするつもりはない。直したければLLMに聞け」とのことです

なるほど、面白いです。でも実用には手を入れる必要がありそうです。

---

## 2. 「これをプレスリリースに使おう」と思った理由

### AIに書かせても「良いか悪いか」わからない問題

プレスリリースをAIに書かせることは、もはや普通になりました。

でも、出てきた原稿が「良い」のか「悪い」のか、判断に困りませんか？

ClaudeとGPTとGeminiに同じ依頼をして、3つの原稿を比較します。でも、どれが一番いいか決められません。「こっちの方が好き」という主観で選んでしまいます。

複数のAIの知恵を借りているのに、最後は人間の勘で決める。

これでいいのでしょうか？

### 実は以前から同じ発想で実験していました

実は以前、同様のコンセプトで実験をしていました。Claude Codeのサブエージェント機能を使い、異なる記者ペルソナにレビューさせるというアプローチです。

→ [Claude Codeで実現するAIエージェントによる究極のプレスリリース作成法](https://gaaaon.jp/blog/claude-code-release)

手応えはありました。でも、もっと洗練された仕組みが欲しかったのです。

そこに天才エンジニアが、同じ発想のOSSを公開してくれました。乗っからない手はありません。

### 「複数AIの議会」という発想は広まりつつあります

ちなみに、複数AIに議論させる「議会」のような仕組みは、深津貴之さんが「[マギシステム](https://note.com/fladdict/n/n106b9ce8f7d4)」として以前から提唱していました。エヴァンゲリオンのMAGIにインスパイアされた、3つのAIペルソナに意思決定させるアプローチです。

中島聡さんが[マルモキャスト](https://www.youtube.com/@marumocast)で語っているように、バイブコーディング時代においてOSSは宝です。動くコードがあれば、すぐに真似できます。理解できます。改造できます。

Karpathy氏のLLM Councilも、まさにそういう存在でした。

---

## 3. 魔改造した点

### なぜLLM Councilをベースにしたか

自前で全部作るより、Karpathy氏のコードをベースにした方が良い理由がいくつかあります。

**1. OpenRouterによる統一API**

LLM Councilは[OpenRouter](https://openrouter.ai/)を使っています。Claude、GPT、Gemini、Grokなど複数のLLMを**単一のAPIで呼び出せる**サービスです。モデルごとに別々のAPIキーを管理する必要がありません。

**2. 並列処理の実装**

複数AIへの問い合わせは`asyncio.gather`で並列実行されています。

```python
# Stage 1: 複数ライターが並列で原稿作成
responses = await query_models_parallel(writer_models, messages)

# Stage 2: 複数評価者が並列で評価
results = await asyncio.gather(*tasks, return_exceptions=True)
```

直列で実行すると4モデル×20評価で膨大な待ち時間になりますが、並列化で大幅に短縮できます。エラー時は指数バックオフでリトライする設計です。

**3. 匿名ランキングの仕組み**

各AIの回答を「案A」「案B」のように匿名化してから評価させます。「Claudeの回答だから高評価」というバイアスを排除できます。

### 付け加えた機能

**3段階ワークフロー**

| Stage | 内容 |
|-------|------|
| Stage 1 | 複数LLMがプレスリリース案を作成 |
| Stage 2 | 5種類の記者ペルソナが匿名評価 |
| Stage 3 | 編集長AIが評価を踏まえて最終版を執筆 |

**5種類の記者ペルソナ**

- **日経新聞記者**: 数字の根拠、競合比較、投資家視点
- **全国紙生活部記者**: 専門用語禁止、消費者メリット重視
- **Webメディア記者**: SEO、シェアラビリティ、スキャンしやすさ
- **業界専門誌記者**: 技術スペック、測定条件、特許情報
- **経済テレビ記者**: 映像映え、60秒で説明できるか

実際の記者に見せる前に、**複数の記者視点でAIにチェックさせる**。それがPress Councilのコンセプトです。

**カスタマイズ機能**

- **LLMマトリクス**: どのAIにどの記者役をさせるか選択可能
- **批判度スライダー**: 寛容〜厳格まで5段階
- **モードプリセット**: シンプル(5評価)/おすすめ(10評価)/フル(20評価)

**日本語対応**

- エラーメッセージの日本語化
- 自動リトライ機能
- 中断ボタン

---

## 4. Appleのプレスリリースで試してみた

（※ここにAppleプレスリリースでの実行結果・スクリーンショットを追加）

### 日経記者の評価

（評価内容）

### 生活部記者の評価

（評価内容）

### 最終的なランキング

（結果）

---

## 5. 使ってわかったこと

### ペルソナの作り込みが全て

Press Councilの精度は、**記者ペルソナの作り込みで決まります**。

単に「日経記者として評価して」ではダメです。以下を定義する必要があります。

- **キャラクター設定**: 名前、年齢、経験年数、バックグラウンド
- **思考プロセス**: 「この記者は何を考えながら読むか」
- **レビュー手順**: 最初の3秒で何を見るか、30秒で何を確認するか
- **レッドフラッグ**: 「これがあったら即却下」のパターン
- **よく聞く質問**: 記者がPR担当に聞きそうな質問リスト

### AIがAI用プロンプトを書くのが最強

ペルソナの作成自体も、ClaudeやClaude Codeのサブエージェント機能で行うのがベターです。

実際、Press Councilの5種類のペルソナは、Claude Codeのサブエージェントとして先に作成し、そのプロンプトをシステムに転用しました。

AIがAI用のプロンプトを書きます。メタですが、これが一番精度が出ます。

---

## 6. これからのプレスリリース

### 良い文章での差別化は終わります

AIを使えば、誰でもそれなりのプレスリリースが書けるようになりました。

文章力での差別化は、もう難しくなっています。

### 読者がヒトからAIへ

記者がプレスリリースを読んで記事を書く時代から、**AIがプレスリリースを読んで記事ドラフトを作る時代**へ移行しつつあります。

となると、プレスリリースの「読者」は人間だけではなくなります。

AIが読んで正しく理解できる構造、AIが重要度を判断できる情報の配置。そういった視点も必要になってきます。

### 本質は「伝えたいかどうか」

結局のところ、AIツールがいくら発達しても、**ニュースバリューがなければ記事にはなりません**。

Press Councilで低評価だった場合、それは「書き方が悪い」のではなく「そもそもニュースとして弱い」可能性があります。

「この発表、本当に世の中に伝えたいことなのか？」

AIツールは、その本質的な問いを突きつけてくれます。

---

## まとめ

Karpathy氏のLLM Councilを魔改造して、プレスリリース専用ツール「Press Council」を作りました。

- 複数AIが原稿を作成
- 5種類の記者ペルソナが匿名評価
- 評価を踏まえて最終版を生成

### 現時点の課題

正直に言うと、まだまだ課題はあります。

- **コストがまだまだ高い**: フルモード（4ライター×20評価）だと1回の実行で数百円かかることも
- **時間がかかる**: 並列処理しても、フル評価だと数分待ちます
- **UIに改善余地あり**: 評価結果の比較表示や、過去リリースとの差分表示など、欲しい機能はまだたくさんあります

### それでも得られた気づき

使ってみて思ったのは、ツールの精度は**ペルソナの作り込み次第**ということです。

そして、どんなに良いツールを使っても、**伝える価値のないものは伝わらない**ということです。

AIは文章を磨いてくれますが、ニュースバリューは人間が作るものです。

---

**GitHub**: [press-council](https://github.com/gaaaon/press-council)

※ 本ツールの開発にはClaude Codeを使用しています

---

#プレスリリース #広報DX #AI活用 #LLM #Claude #Karpathy
